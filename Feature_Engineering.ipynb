{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "1. What is a parameter?\n",
        "   - A parameter in feature engineering is a setting that affects how a feature is created or modified.\n",
        "   - For example:\n",
        "     - In scaling, the mean and standard deviation are parameters.\n",
        "     - In binning, the number of bins is a parameter.\n",
        "   - These values are chosen before training and help transform data for better model performance.\n",
        "\n",
        "2. What is correlation? What does negative correlation mean?\n",
        "   - Correlation measures the relationship between two variables, showing how they move together.\n",
        "     - Positive correlation: Both variables increase or decrease together.\n",
        "     - Negative correlation: One variable increases while the other decreases.\n",
        "   - For example, temperature & hot coffee sales have a negative correlation- as temperature rises, coffee sales drop.\n",
        "\n",
        "3. Define Machine Learning. What are the main components in Machine Learning?\n",
        "   - Machine Learning is a method where computers learn patterns from data to make predictions or decisions without being explicitly programmed.\n",
        "   - Main components of ML:\n",
        "     - Data - Raw information used for training.\n",
        "     - Features - Important attributes extracted from data.\n",
        "     - Model - An algorithm that learns from data.\n",
        "     - Training - Process of teaching the model using data.\n",
        "     - Evaluation - Testing the model's accuracy and performance.\n",
        "     - Prediciton - Using the trained model to make decisions.\n",
        "\n",
        "4. How does loss value help in determining whether the model is good or not?\n",
        "   - The loss value measures how far the model's predictions are from the actual values.\n",
        "     - Low loss = The model is making accurate predictions(good model).\n",
        "     - High loss = The model has errors and needs improvement.\n",
        "   - It helps in tuning the model by adjusting parameters to reduce errors.\n",
        "\n",
        "5. What are continuous and categorical variables?\n",
        "   - Continuous variables:\n",
        "     - A variable that can take any numerical value within a range.\n",
        "       - Example: Height, weight, temperature.\n",
        "   - Categorical variables:\n",
        "     - A variable that represents distinct groups or categories.\n",
        "       - Example: Gender(Male/Female), Colors(Red/Blue/Green).\n",
        "\n",
        "6. How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "   - Categorical variables need to be converted into numerical form for ML models.\n",
        "   - Common Techniques:\n",
        "     - Label Encoding - Assigns a unique number to each category(e.g., Male -> 0, Female -> 1).\n",
        "     - One-Hot Encoding - Creates separate binary columns for each category(e.g., Red -> [1,0,0], Blue -> [0,1,0]).\n",
        "     - Ordinal Encoding - Assigns numbers based on order(e.g., Small -> 1, Medium -> 2, Large -> 3).\n",
        "     - Frequency Encoding - Replaces categories with their occurence count.\n",
        "     - Target Encoding - Replaces categories with the mean of the target variable.\n",
        "\n",
        "7. What do you mean by training and testing a dataset?\n",
        "   - Training Dataset: Used to teach the model by finding patterns in the data.\n",
        "   - Testing Dataset: Used to evaluate the model's performance on unseen data.\n",
        "   - Example:\n",
        "     - If you're training a model to recognize cats and dogs.\n",
        "       - The training set helps the model learn the difference.\n",
        "       - The testing set checks if the model correctly identifies new images.\n",
        "\n",
        "8. What is sklearn.preprocessing?\n",
        "   - sklearn.preprocessing is a module in Scikit-Learn that provides tools for scaling, transforming, and encoding data before training a machine learning model.\n",
        "   - Common functions\n",
        "     - StandardScaler - Standardizes data(mean = 0, std = 1).\n",
        "     - MinMaxScaler - Scales data to a fixed range (e.g., 0 to 1).\n",
        "     - LabelEncoder - Converts categorical labels into numbers.\n",
        "     - OneHotEncoder - Converts categories into binary vectors.\n",
        "     - Binarizer - Converts values into 0s and 1s based on threshold.\n",
        "   - It helps improve model performance by making data suitable for learning.\n",
        "\n",
        "9. What is a Test set?\n",
        "   - A test set is a portion of the dataset used to evaluate a trained machine learning model. It contains unseen data to check how well the model performs on new inputs.\n",
        "   - Example: If training a model recognize cats and dogs, the test set includes new images the model hasn't seen before to measure accuracy.\n",
        "\n",
        "10. How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "    - In Python, we use train_test_split from sklearn.model_selection to split data into training and testing sets.\n",
        "    - Example:\n",
        "              from sklearn.model_selection import train_test_split\n",
        "\n",
        "              X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    - Explanation:\n",
        "      - X, y -> Features and target variable\n",
        "      - test_size=0.2 -> 20% of data for testing, 80% for training.\n",
        "      - random_state=42 -> Ensure reproducibilty\n",
        "\n",
        "    - This helps train the model on one part and test it on unseen data.\n",
        "    - Approach to a Machine Learning Problem:\n",
        "      - Define the Problem - Understand the goal and data requirements.\n",
        "      - Collect Data - Gather relevant and high-quality data.\n",
        "      - Preprocess Data - Handle missing values, remove duplicates, and clean data.\n",
        "      - Feature Engineering - Select, create, and transform features.\n",
        "      - Split Data - Divide into training and testing sets.\n",
        "      - Choose a Model - Select the right algorithm based on the problem.\n",
        "      - Train the Model - Fit the model using the training data.\n",
        "      - Evaluate the Model - Test performance using the test data.\n",
        "      - Tune the Model - Optimize hyperparameters for better accuracy.\n",
        "      - Deploy and Monitor - Use the model in real-world applications and track its performance.\n",
        "    - This structured approach ensures a systematic and effective ML solution.\n",
        "\n",
        "11. Why do we have to perform EDA before fitting a model to the data?\n",
        "    - Exploratory Data Analysis (EDA) helps us understand the dataset before training a model. It is important because:\n",
        "      - Detects Missing Values - Helps handle incomplete data.\n",
        "      - Finds Outliers - Identifies unusual values that may affect the model.\n",
        "      - Understands Data Distribution - Checks patterns, trends, and relationships.\n",
        "      - Identifies Feature Importance - Helps select the right features for training.\n",
        "      - Prevents Data Leakage - Ensures proper data splitting and avoids biased models.\n",
        "    - EDA improves model accuracy by ensuring clean, well-structured data.\n",
        "\n",
        "12. What is correlation?\n",
        "    - Correlation measures the relationship between two variables and how they move together.\n",
        "      - Positive Correlation: Both variables increase or decrease together.\n",
        "      - Negative Correlation: One variable increases while the other decreases.\n",
        "      - Zero Correlation: No relationship between variables.\n",
        "    - Example:\n",
        "      - Height & Weight → Positive Correlation\n",
        "      - emperature & Hot Coffee Sales → Negative Correlation\n",
        "\n",
        "13. What does negative correlation mean?\n",
        "    - Negative correlation means that as one variable increases, the other decreases (or vice versa).\n",
        "    - Example:\n",
        "      - Temperature & Hot Coffee Sales → As temperature rises, coffee sales drop.\n",
        "      - Exercise Time & Body Weight → More exercise leads to lower weight.\n",
        "    - A stronger negative correlation (closer to -1) means a stronger inverse relationship.\n",
        "\n",
        "14. How can you find correlation between variables in Python?\n",
        "    - Use Pandas and NumPy to calculate correlation between variables.\n",
        "    - Example:\n",
        "             import pandas as pd\n",
        "\n",
        "             # Sample DataFrame\n",
        "             data = {'A': [1, 2, 3, 4], 'B': [4, 3, 2, 1]}\n",
        "             df = pd.DataFrame(data)\n",
        "\n",
        "             # Calculate correlation\n",
        "             correlation_matrix = df.corr()\n",
        "             print(correlation_matrix)\n",
        "\n",
        "    - Other Methods:\n",
        "      - Pearson Correlation (default in .corr()) - Measures linear relationship.\n",
        "      - Spearman & Kendall Correlation - Used for ranked or non-linear data.\n",
        "             df.corr(method='spearman')  # Spearman correlation\n",
        "             df.corr(method='kendall')   # Kendall correlation\n",
        "\n",
        "    - This helps understand relationships between variables in datasets.\n",
        "\n",
        "15. What is causation? Explain difference between correlation and causation with an example.\n",
        "  - Causation means that one event directly causes another to happen.\n",
        "  - Difference Between Correlation and Causation\n",
        "    - Correlation: Two variables move together but one does not necessarily cause the other.\n",
        "    - Causation: One variable directly affects the other.\n",
        "  - Example:\n",
        "    - Correlation: Ice cream sales and drowning cases increase together.\n",
        "      - But eating ice cream doesn't cause drowning (summer heat is the real factor).\n",
        "    - Causation: More exercise leads to weight loss.\n",
        "      - Here, exercise directly causes weight loss.\n",
        "    - Key Rule: Correlation does not imply causation!\n",
        "\n",
        "16. What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "   - An optimizer in machine learning adjusts the model's parameters (weights) to minimize the loss function and improve accuracy.\n",
        "     - Types of Optimizers:\n",
        "   - Gradient Descent (GD)\n",
        "       - Updates weights using the entire dataset.\n",
        "       - Example: Used in simple regression models.\n",
        "   - Stochastic Gradient Descent (SGD)\n",
        "       - Updates weights using one random sample at a time.\n",
        "       - Example: Used in online learning and large datasets.\n",
        "   - Mini-Batch Gradient Descent\n",
        "       - Updates weights using small batches of data.\n",
        "       - Example: Used in deep learning for efficiency.\n",
        "   - Adam (Adaptive Moment Estimation)\n",
        "       - Combines momentum and adaptive learning rates for faster convergence.\n",
        "       - Example: Used in deep learning models like CNNs and RNNs.\n",
        "   - RMSprop (Root Mean Square Propagation)\n",
        "       - Adjusts learning rates based on recent gradients, preventing large updates.\n",
        "       - Example: Works well for recurrent neural networks (RNNs).\n",
        "   - Adagrad (Adaptive Gradient Algorithm)\n",
        "       - Adapts learning rate based on past gradients, useful for sparse data.\n",
        "       - Example: Used in NLP and recommendation systems.\n",
        "   - Each optimizer helps improve model performance based on the problem and dataset.\n",
        "\n",
        "17. What is sklearn.linear_model?\n",
        "    - sklearn.linear_model is a module in Scikit-Learn that provides various linear models for regression and classification tasks.\n",
        "    - Common Models:\n",
        "      - a. LinearRegression - Fits a straight line to predict continuous values.\n",
        "              from sklearn.linear_model import LinearRegression\n",
        "              model = LinearRegression()\n",
        "      - b. LogisticRegression - Used for binary/multi-class classification.\n",
        "              from sklearn.linear_model import LogisticRegression\n",
        "              model = LogisticRegression()\n",
        "      - c. Ridge & Lasso Regression - Linear regression with regularization to prevent overfitting.\n",
        "              from sklearn.linear_model import Ridge, Lasso\n",
        "              ridge_model = Ridge(alpha=1.0)\n",
        "              lasso_model = Lasso(alpha=0.1)\n",
        "      - d. SGDClassifier & SGDRegressor - Uses Stochastic Gradient Descent for large datasets.\n",
        "              from sklearn.linear_model import SGDClassifier, SGDRegressor\n",
        "              clf = SGDClassifier()\n",
        "              reg = SGDRegressor()\n",
        "\n",
        "      - This module is useful for solving regression and classification problems efficiently.\n",
        "\n",
        "18. What does model.fit() do? What arguments must be given?\n",
        "    - model.fit() trains a machine learning model by learning patterns from the given data. It adjusts model parameters to minimize errors.\n",
        "    - Required Arguments:\n",
        "      - X (Features/Input Data) - The independent variables.\n",
        "      - y (Target/Labels) - The dependent variable (what we want to predict).\n",
        "    - Example:\n",
        "              from sklearn.linear_model import LinearRegression\n",
        "\n",
        "              model = LinearRegression()\n",
        "              model.fit(X_train, y_train)  # Training the model\n",
        "    - Once trained, the model can make predictions using .predict().\n",
        "\n",
        "19. What does model.predict() do? What arguments must be given?\n",
        "    - model.predict() makes predictions using the trained model on new or unseen data.\n",
        "    - Required Argument:\n",
        "      - X (Features/Input Data) - The data for which predictions are needed.\n",
        "    - Example:\n",
        "              y_pred = model.predict(X_test)  # Predicting on test data\n",
        "    - It outputs predicted values based on learned patterns.\n",
        "\n",
        "20. What are continuous and categorical variables?\n",
        "    - Continuous Variables\n",
        "      - Can take any numeric value within a range.\n",
        "      - Example: Height, weight, temperature.\n",
        "    - Categorical Variables\n",
        "      - Represent distinct groups or categories.\n",
        "      - Example: Gender (Male/Female), Colors (Red/Blue/Green).\n",
        "    - Key Difference: Continuous variables are measured, while categorical variables are grouped.\n",
        "\n",
        "21. What is feature scaling? How does it help in Machine Learning?\n",
        "    - Feature scaling is the process of normalizing or standardizing numerical data so that all features have a similar scale.\n",
        "    - How Does It Help in Machine Learning?\n",
        "      - Improves Model Performance - Prevents features with larger values from dominating.\n",
        "      - Speeds Up Training - Helps gradient-based models converge faster.\n",
        "      - Better Distance Calculations - Essential for algorithms like KNN and K-Means.\n",
        "    - Common Methods:\n",
        "      - Standardization (StandardScaler) - Scales data to have mean = 0 and std = 1.\n",
        "      - Normalization (MinMaxScaler) - Scales data between 0 and 1.\n",
        "    - Example:\n",
        "             from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "             scaler = StandardScaler()\n",
        "             X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    - Feature scaling ensures fair comparisons and better model accuracy.\n",
        "\n",
        "22. How do we perform scaling in Python?\n",
        "    - Use sklearn.preprocessing for feature scaling.\n",
        "    - Standardization (StandardScaler)\n",
        "      - Scales data to have mean = 0 and standard deviation = 1.\n",
        "            from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "            scaler = StandardScaler()\n",
        "            X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    - Normalization (MinMaxScaler)\n",
        "      - Scales data between 0 and 1.\n",
        "           from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "           scaler = MinMaxScaler()\n",
        "           X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    - Feature scaling helps improve model performance and training speed.\n",
        "\n",
        "23. What is sklearn.preprocessing?\n",
        "    - sklearn.preprocessing is a module that provides tools for scaling, transforming, and encoding data before training a machine learning model.\n",
        "    - Common Functions:\n",
        "      - StandardScaler - Standardizes data (mean = 0, std = 1).\n",
        "      - MinMaxScaler - Scales data between 0 and 1.\n",
        "      - LabelEncoder - Converts categorical labels into numbers.\n",
        "      - OneHotEncoder - Converts categorical data into binary vectors.\n",
        "      - Binarizer - Converts values into 0s and 1s based on a threshold.\n",
        "    - Example:\n",
        "             from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "             scaler = StandardScaler()\n",
        "             X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    - It helps make data suitable for machine learning models.\n",
        "\n",
        "24. How do we split data for model fitting (training and testing) in Python?\n",
        "    - In Python, we use train_test_split from sklearn.model_selection to split data into training and testing sets.\n",
        "    - Example:\n",
        "              from sklearn.model_selection import train_test_split\n",
        "\n",
        "              X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "    - Explanation:\n",
        "      - X, y -> Features and target variable\n",
        "      - test_size=0.2 -> 20% of data for testing, 80% for training.\n",
        "      - random_state=42 -> Ensure reproducibilty\n",
        "\n",
        "    - This helps train the model on one part and test it on unseen data.\n",
        "\n",
        "25. Explain data encoding?\n",
        "    - Data encoding is the process of converting categorical data into numerical format so machine learning models can understand it.\n",
        "    - Common Encoding Methods:\n",
        "      - a. Label Encoding - Assigns a unique number to each category.\n",
        "            from sklearn.preprocessing import LabelEncoder\n",
        "            encoder = LabelEncoder()\n",
        "            y_encoded = encoder.fit_transform(y)\n",
        "      - b. One-Hot Encoding - Converts categories into binary vectors.\n",
        "            from sklearn.preprocessing import OneHotEncoder\n",
        "            encoder = OneHotEncoder(sparse=False)\n",
        "            X_encoded = encoder.fit_transform(X)\n",
        "      - c. Ordinal Encoding - Assigns numbers based on category order (for ranked data).\n",
        "      - d. Target Encoding - Replaces categories with the mean of the target variable.\n",
        "    - Encoding ensures categorical data is properly used in ML models.\n",
        "\n",
        "\n",
        "          \n",
        "\n",
        "\n",
        "             \n",
        "        \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "   \n",
        "\n"
      ],
      "metadata": {
        "id": "mD03I9ePUKOn"
      }
    }
  ]
}